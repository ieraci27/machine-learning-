{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d6b7d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 0.7231636462303825\n",
      "Testing MSE: 0.670288340179917\n",
      "Model formula: f(x) = 1.31 + -0.05*x1 + -0.58*x2 + 0.47*sin(x2) + 0.04*x1*x2\n",
      "50/50 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 930us/step\n",
      "Mean Squared Error on training set: 0.10\n",
      "Mean Squared Error on test set: 0.12\n",
      "44/44 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "Training MSE: 0.014624534459571237\n",
      "Test MSE: 0.01762934118616797\n"
     ]
    }
   ],
   "source": [
    "##TASK1 \n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from math import sin\n",
    "import pickle\n",
    "\n",
    "url = 'https://drive.switch.ch/index.php/s/TeDwnbYsBKRuJjv/download'  \n",
    "response = requests.get(url)\n",
    "data = np.load(io.BytesIO(response.content))\n",
    "\n",
    "# x is a Numpy array of shape (n_samples, n_features) with the inputs\n",
    "x = data.f.x\n",
    "\n",
    "# y is a Numpy array of shape (n_samples, ) with the targets\n",
    "y = data.f.y\n",
    "\n",
    "# Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# call the model \n",
    "model = LinearRegression()\n",
    "\n",
    "#define the np array that contains the model for the training set\n",
    "x_train_compact = np.column_stack((x_train[:, 0],x_train[:, 1], np.sin(x_train[:, 1]), x_train[:, 0]*x_train[:, 1]))\n",
    "                                                                                             \n",
    "#fit the data\n",
    "model.fit(x_train_compact, y_train)\n",
    "\n",
    "#define the np array that contains the model for the test set\n",
    "x_test_compact = np.column_stack((x_test[:, 0],x_test[:, 1], np.sin(x_test[:, 1]), x_test[:, 0]*x_test[:, 1]))\n",
    "\n",
    "#making predictions\n",
    "test_predictions = model.predict(x_test_compact)\n",
    "train_predictions = model.predict(x_train_compact)\n",
    "\n",
    "#compute the mean squared error for the train and test sets\n",
    "train_mse = mean_squared_error(y_train, train_predictions)\n",
    "test_mse = mean_squared_error(y_test, test_predictions)\n",
    "\n",
    "#print results\n",
    "print(\"Training MSE:\",train_mse )\n",
    "print(\"Testing MSE:\",test_mse )\n",
    "\n",
    "# Print the formula of the model \n",
    "theta = np.append(model.intercept_, model.coef_)\n",
    "print(f\"Model formula: f(x) = {theta[0]:.2f} + {theta[1]:.2f}*x1 + {theta[2]:.2f}*x2 + {theta[3]:.2f}*sin(x2) + {theta[4]:.2f}*x1*x2\")\n",
    "\n",
    "# Save the model as a pickle file\n",
    "with open('model_task1', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "###########################################################################\n",
    "\n",
    "##TASK2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import io\n",
    "import requests\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from math import sin\n",
    "import pickle\n",
    "\n",
    "url = 'https://drive.switch.ch/index.php/s/TeDwnbYsBKRuJjv/download'  # Data location\n",
    "response = requests.get(url)\n",
    "data = np.load(io.BytesIO(response.content))\n",
    "\n",
    "# x is a Numpy array of shape (n_samples, n_features) with the inputs\n",
    "x = data.f.x\n",
    "\n",
    "# y is a Numpy array of shape (n_samples, ) with the targets\n",
    "y = data.f.y\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#create the array for the model for the training set \n",
    "x1_train = x_train[:,0].reshape(-1,1) # values of the first column\n",
    "x2_train = x_train[:,1].reshape(-1,1)# values of the second column\n",
    "x3_train= np.sin(x2_train)\n",
    "x4_train = x1_train*x2_train \n",
    "x_compact_train = np.hstack((np.ones((x_train.shape[0],1)), x1_train,x2_train,x3_train,x4_train)) # The compact input\n",
    "\n",
    "#create the array for the model for the test set \n",
    "x1_test = x_test[:,0].reshape(-1,1) # values of the first column\n",
    "x2_test= x_test[:,1].reshape(-1,1)# values of the second column\n",
    "x3_test= np.sin(x2_test)\n",
    "x4_test = x1_test*x2_test\n",
    "x_compact_test = np.hstack((np.ones((x_test.shape[0],1)), x1_test,x2_test,x3_test,x4_test)) # The compact input\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=5, activation='relu')) #input layer with relu activation function\n",
    "model.add(Dense(10, activation='relu')) #hidden layer with relu activation function\n",
    "model.add(Dense(1)) #output layer\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd') #stochastic gradient descent optimizer\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_compact_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "# Predict on the training and test sets\n",
    "train_predictions = model.predict(x_compact_train)\n",
    "test_predictions = model.predict(x_compact_test)\n",
    "\n",
    "# Evaluate the model on the training and test set \n",
    "mse_test = mean_squared_error(y_test, test_predictions)\n",
    "mse_train = mean_squared_error(y_train, train_predictions)\n",
    "\n",
    "#print the results \n",
    "print(f\"Mean Squared Error on training set: {mse_train:.2f}\")\n",
    "print(f\"Mean Squared Error on test set: {mse_test:.2f}\")\n",
    "\n",
    "#Save the model as a pickle file\n",
    "with open('model_task2', 'wb') as f:\n",
    "     pickle.dump(model, f)\n",
    "    \n",
    "########################################################################### \n",
    "\n",
    "##MODEL TASK3\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "from math import sin\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "url = 'https://drive.switch.ch/index.php/s/TeDwnbYsBKRuJjv/download'  # Data location\n",
    "response = requests.get(url)\n",
    "data = np.load(io.BytesIO(response.content))\n",
    "\n",
    "#set seed \n",
    "random.seed(234)\n",
    "np.random.seed(234)\n",
    "tf.random.set_seed(234)\n",
    "\n",
    "#x is a Numpy array of shape (n_samples, n_features) with the inputs\n",
    "x = data.f.x\n",
    "\n",
    "#y is a Numpy array of shape (n_samples, ) with the targets\n",
    "y = data.f.y\n",
    "\n",
    "#Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#Build the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=2, activation='relu'))  #input layer with relu activation\n",
    "model.add(Dense(32, activation='relu')) #first hidden layer with relu activation\n",
    "model.add(Dense(16, activation='relu')) #second hidden layer with relu activation\n",
    "model.add(Dense(1))  #Output layer\n",
    "\n",
    "#Compile the model\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "#Train the model\n",
    "model.fit(x_train, y_train, epochs=300, batch_size=32, validation_split=0.1, verbose = 0)\n",
    "\n",
    "#Use the model to make predictions on the training and test sets\n",
    "y_train_pred = model.predict(x_train)\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "#Evaluate the model on the training and test sets\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test,y_test_pred)\n",
    "\n",
    "#print the results \n",
    "print(\"Training MSE:\", train_mse)\n",
    "print(\"Test MSE:\", test_mse)\n",
    "\n",
    "#Save the model as a pickle file\n",
    "with open('model_task3', 'wb') as f:\n",
    "    pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02707946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step\n",
      "MSE on whole dataset: 0.015525976477550255\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import joblib\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluates the mean squared error between the values in y_true and the values\n",
    "    in y_pred.\n",
    "    ### YOU CAN NOT EDIT THIS FUNCTION ###\n",
    "    :param y_true: Numpy array, the true target values from the test set;\n",
    "    :param y_pred: Numpy array, the values predicted by your model.\n",
    "    :return: float, the mean squared error between the two arrays.\n",
    "    \"\"\"\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "\n",
    "def load_model(filename):\n",
    "    \"\"\"\n",
    "    Loads a Scikit-learn model saved with joblib.dump.\n",
    "    This is just an example, you can write your own function to load the model.\n",
    "    Some examples can be found in src/utils.py.\n",
    "    :param filename: string, path to the file storing the model.\n",
    "    :return: the model.\n",
    "    \"\"\"\n",
    "    model = joblib.load(filename)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Load the data\n",
    "# This will be replaced with our private test data when grading the assignment\n",
    "\n",
    "# Load data from url\n",
    "url = 'https://drive.switch.ch/index.php/s/TeDwnbYsBKRuJjv/download'\n",
    "response = requests.get(url)\n",
    "data = np.load(io.BytesIO(response.content))\n",
    "\n",
    "# Alternatively yo can load the data from file\n",
    "# data_path = '../data/data.npz'\n",
    "# data = np.load(data_path)\n",
    "\n",
    "##################################################################### \n",
    "\n",
    "## Preprocessing data for task1\n",
    "#x = data.f.x\n",
    "#x_compact = np.column_stack((x[:, 0],x[:, 1], np.sin(x[:, 1]), x[:, 0]*x[:, 1]))\n",
    "                       \n",
    "## y is a Numpy array of shape (n_samples, ) with the targets\n",
    "#y = data.f.y\n",
    "\n",
    "## Load the trained model\n",
    "#baseline_model_path = './model_task1'\n",
    "#baseline_model = load_model(baseline_model_path)\n",
    "\n",
    "## Predict on the given samples\n",
    "#y_pred = baseline_model.predict(x_compact)\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "## Preprocessing data for task2 \n",
    "#x = data.f.x\n",
    "#x1= x[:,0].reshape(-1,1) # values of the first column\n",
    "#x2 = x[:,1].reshape(-1,1)# values of the second column\n",
    "#x3= np.sin(x2)\n",
    "#x4= x1*x2\n",
    "\n",
    "#x_compact = np.hstack((np.ones((x.shape[0],1)), x1, x2, x3, x4)) # The compact input\n",
    "\n",
    "## y is a Numpy array of shape (n_samples, ) with the targets\n",
    "#y = data.f.y\n",
    "#y = y.reshape(-1,1)\n",
    "\n",
    "## Load the trained model\n",
    "#baseline_model_path = './model_task2'\n",
    "#baseline_model = load_model(baseline_model_path)\n",
    "\n",
    "## Predict on the given samples\n",
    "#y_pred = baseline_model.predict(x_compact)\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "##CODE FOR TASK3\n",
    "\n",
    "# x is a Numpy array of shape (n_samples, n_features) with the inputs\n",
    "x = data.f.x\n",
    "# y is a Numpy array of shape (n_samples, ) with the targets\n",
    "y = data.f.y\n",
    "\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "# Load the trained model\n",
    "baseline_model_path = './model_task3' \n",
    "baseline_model = load_model(baseline_model_path)\n",
    "\n",
    "# Predict on the given samples\n",
    "y_pred = baseline_model.predict(x)\n",
    "\n",
    "############################################################################\n",
    "# STOP EDITABLE SECTION: do not modify anything below this point.\n",
    "############################################################################\n",
    "\n",
    "# Evaluate the prediction using MSE\n",
    "mse = evaluate_predictions(y_pred, y)\n",
    "print(f'MSE on whole dataset: {mse}')\n",
    "\n",
    "# NOTE: NOW THIS CELL IS NOT WORKING SINCE YOU NEED TO CHANGE THE INPUT.\n",
    "# DO IT AND EVERYTHING RUNS SMOOTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a558de5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
